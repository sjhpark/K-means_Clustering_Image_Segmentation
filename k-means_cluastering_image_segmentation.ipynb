{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means Clustering for Pixel-wise Image Segmentation\n",
    "This is pixel-wise segmentation and is not semantic segmentation. \n",
    "\n",
    "While semantic segmentation has clusters of pixels that are semantically similar, pixel-wise segmentation has clusters of pixels that are similar in color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image:   2%|▏         | 1/50 [00:00<00:07,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: all centroids have converged before max iteration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image:   4%|▍         | 2/50 [00:01<00:27,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11: all centroids have converged before max iteration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image:   8%|▊         | 4/50 [00:04<01:05,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17: all centroids have converged before max iteration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image:  20%|██        | 10/50 [00:25<02:25,  3.65s/it]c:\\Users\\whdqk\\anaconda3\\envs\\sam\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\whdqk\\anaconda3\\envs\\sam\\lib\\site-packages\\numpy\\core\\_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "Image: 100%|██████████| 50/50 [09:32<00:00, 11.45s/it]\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "n_clusters_list = np.arange(1,51) # number of clusters\n",
    "max_iter = 20 # maximum number of iterations\n",
    "threshold = 0.1 # threshold for convergence\n",
    "eps = 1e-8 # epsilon for numerical stability\n",
    "np.random.seed(42) # set seed for reproducibility\n",
    "\n",
    "# define image directory\n",
    "image_dir = \"rectified_images/Kitti_Stereo_2015/data_scene_flow/testing/image_2/\"\n",
    "\n",
    "# list of images\n",
    "image_list = []\n",
    "\n",
    "for n_clusters in tqdm(n_clusters_list, desc=\"Image\"):\n",
    "\n",
    "    # sample image\n",
    "    image_sample = image_dir + os.listdir(image_dir)[49]\n",
    "\n",
    "    # read image\n",
    "    image = cv2.imread(image_sample)\n",
    "\n",
    "    # convert image to RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # shape of image\n",
    "    width = image.shape[0] # width\n",
    "    height = image.shape[1] # height \n",
    "    channels = image.shape[2] # channels\n",
    "\n",
    "    # reshape image\n",
    "    image = image.reshape(width*height, channels)\n",
    "\n",
    "    ################### K-MEANS CLUSTERING ###################\n",
    "    centers = np.zeros((n_clusters, channels)) # centroids\n",
    "    centers_old = centers.copy() # centroids from previous iteration\n",
    "\n",
    "    # Randomly initialize cluster centers (centroids)\n",
    "    for i in range(n_clusters):\n",
    "        # randomly pick a set of R G B pixels as each centroid\n",
    "        # ex) centroid 1 = [R220, G220, B220]\n",
    "        # ex) centroid 2 = [R81, G81, B81]\n",
    "        centers[i] = image[np.random.choice(image.shape[0], replace=False)]\n",
    "\n",
    "    # Update cluster centers until convergence\n",
    "    for i in range(max_iter):\n",
    "\n",
    "        # intialize previous centroids\n",
    "        centers_old = centers.copy()\n",
    "\n",
    "        # L2 distance between each of the pixels and each of the centroids\n",
    "        # distances.shape = (width*height, n_clusters)\n",
    "        distances = np.linalg.norm(image[:, None] - centers, axis=2)\n",
    "\n",
    "        # indices of the closest centroids for each of the pixels\n",
    "        labels = np.argmin(distances, axis=1) \n",
    "\n",
    "        # update centroids\n",
    "        for j in range(n_clusters):\n",
    "            # update: centroid_n = 1/N * Sigma(x_i) \n",
    "            # (where x_i is the pixel that belongs to centroid_n)\n",
    "            centers[j] = np.mean(image[labels == j], axis=0)\n",
    "\n",
    "            # Some pixels may not belong to any cluster and their mean will be NaN.\n",
    "            # Thus, convert NaN to 0 and add epsilon.\n",
    "            centers[j] = np.nan_to_num(centers[j]) + eps\n",
    "\n",
    "        # print(\"distance between current center and previous center: \", np.linalg.norm(centers - centers_old))\n",
    "\n",
    "        # check for convergence\n",
    "        if np.linalg.norm(centers - centers_old) < threshold:\n",
    "            print(f\"Iteration {i}: all centroids have converged before max iteration.\")\n",
    "            break # break out of for-loop\n",
    "\n",
    "    # Assign random color to each cluster\n",
    "    segmented_data = np.zeros((width*height, channels)) # color-based segmented image\n",
    "    new_colors = np.random.randint(0, 255, size=(n_clusters, channels)) # random colors\n",
    "    for i in range(n_clusters):\n",
    "        # assign each random color to the pixel belonging to each cluster\n",
    "        segmented_data[labels == i] = new_colors[i]\n",
    "\n",
    "    # Reshape segmented data to original image shape\n",
    "    segmented_image = segmented_data.reshape((width, height, channels)).astype('uint8')\n",
    "\n",
    "    ##############################################################\n",
    "\n",
    "    # Append segmented image to image list\n",
    "    image_list.append(segmented_image)\n",
    "\n",
    "\n",
    "###################### CREATE a GIF ######################\n",
    "frames = [] # frames\n",
    "font = ImageFont.truetype(\"impact.ttf\", 40) # font\n",
    "\n",
    "# Add title and append each frame to the list of frames\n",
    "for i, img in enumerate(image_list):\n",
    "    # Open image\n",
    "    image = Image.fromarray(img)\n",
    "\n",
    "    # Add title as text overlay\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.text((10, 10), f\"Number of clusters: {n_clusters_list[i]}\", font=font)\n",
    "\n",
    "    # Append frame to list of frames\n",
    "    frames.append(image)\n",
    "\n",
    "# Greate and save a GIF\n",
    "frames[0].save('segmented_image.gif', format='GIF', append_images=frames[1:], save_all=True, duration=1000, loop=10)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
